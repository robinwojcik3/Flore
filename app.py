#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Streamlit app : r√©cup√©ration automatis√©e d‚Äôinformations botaniques

Auteur : Robin Wojcik (Am√©ten)
Date   : 2025-05-28 (v0.9.1 - Am√©lioration chargement CSV et onglet INPN)

Fonctionnement actualis√© (v0.9.1)
----------------------------------
* Mode d√©bogage activable via `?debug=true` dans l'URL pour des logs plus d√©taill√©s.
* Logique de scraping pour FloreAlpes (requests+BeautifulSoup) maintenue et comment√©e.
* S√©lecteurs d'images et extraction de tableaux l√©g√®rement affin√©s.
* Abandon complet de Selenium au profit de `requests` pour la portabilit√©.
* Interface utilisateur et messages d'erreur revus pour plus de clart√©.
* R√©cup√©ration des CD_REF via un fichier CSV local "DATA_CD_REF.csv" avec d√©tection am√©lior√©e du d√©limiteur.
* Ajout d'un onglet pour afficher les informations de l'INPN.
"""

from __future__ import annotations

import pandas as pd
import requests
import streamlit as st
from bs4 import BeautifulSoup
from urllib.parse import quote_plus, urljoin
import os

# -----------------------------------------------------------------------------
# Configuration globale et Mode D√©bogage
# -----------------------------------------------------------------------------

st.set_page_config(page_title="Auto-scraper esp√®ces", layout="wide", page_icon="üåø")

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
}

CD_REF_CSV_PATH = "DATA_CD_REF.csv"

def is_debug_mode() -> bool:
    """V√©rifie si le mode d√©bogage est activ√© via les param√®tres de requ√™te URL."""
    try:
        if hasattr(st, 'query_params'):
            return "true" in st.query_params.get_all("debug")
        if hasattr(st, 'experimental_get_query_params'):
            query_params = st.experimental_get_query_params()
            return "true" in query_params.get("debug", [])
        return False
    except Exception:
        return False

DEBUG_MODE = is_debug_mode()

# -----------------------------------------------------------------------------
# Chargement des donn√©es CD_REF depuis CSV (Version am√©lior√©e)
# -----------------------------------------------------------------------------

@st.cache_data(show_spinner="Chargement initial des donn√©es TaxRef locales...")
def load_cd_ref_data(csv_path: str) -> pd.DataFrame | None:
    """Charge les donn√©es CD_REF et NOM LATIN depuis le fichier CSV sp√©cifi√©,
       en essayant plusieurs d√©limiteurs courants."""
    df = None
    # D√©limiteurs courants √† essayer
    possible_delimiters = [',', '\t', ';'] 

    for delimiter in possible_delimiters:
        try:
            if DEBUG_MODE:
                st.info(f"[DEBUG load_cd_ref_data] Tentative de lecture de '{csv_path}' avec d√©limiteur '{repr(delimiter)}' et header=1.")
            
            # Lire le CSV en utilisant la deuxi√®me ligne (index 1) comme en-t√™tes
            current_df = pd.read_csv(
                csv_path, 
                header=1, 
                dtype=str, # Lire toutes les colonnes comme cha√Ænes initialement pour √©viter les erreurs de type
                delimiter=delimiter,
                on_bad_lines='skip', # Ignorer les lignes potentiellement malform√©es
                skipinitialspace=True # Ignorer les espaces apr√®s le d√©limiteur
            )

            if DEBUG_MODE:
                st.info(f"[DEBUG load_cd_ref_data] Colonnes lues avec d√©limiteur '{repr(delimiter)}': {current_df.columns.tolist()}")

            # Nettoyer les noms des colonnes lues (supprimer les espaces superflus)
            actual_columns = [str(col).strip() for col in current_df.columns]
            current_df.columns = actual_columns # Appliquer les noms de colonnes nettoy√©s

            # Sc√©nario 1: Les colonnes sont d√©j√† nomm√©es "CD_REF" et "NOM LATIN"
            if "CD_REF" in actual_columns and "NOM LATIN" in actual_columns:
                df = current_df[["CD_REF", "NOM LATIN"]].copy()
                if DEBUG_MODE:
                    st.info(f"[DEBUG load_cd_ref_data] Colonnes 'CD_REF' et 'NOM LATIN' trouv√©es directement avec d√©limiteur '{repr(delimiter)}'.")
                break  # Le bon d√©limiteur et les bonnes colonnes ont √©t√© trouv√©s

            # Sc√©nario 2: Il y a au moins deux colonnes, on suppose que ce sont les bonnes dans le bon ordre
            elif len(actual_columns) >= 2:
                temp_df = current_df.copy()
                original_first_col_name = actual_columns[0]
                original_second_col_name = actual_columns[1]
                
                # Renommer les deux premi√®res colonnes
                temp_df = temp_df.rename(columns={
                    original_first_col_name: "CD_REF",
                    original_second_col_name: "NOM LATIN"
                })
                
                # V√©rifier si le renommage a bien cr√©√© les colonnes attendues
                if "CD_REF" in temp_df.columns and "NOM LATIN" in temp_df.columns:
                    df = temp_df[["CD_REF", "NOM LATIN"]].copy()
                    if DEBUG_MODE:
                        st.info(f"[DEBUG load_cd_ref_data] Colonnes renomm√©es en 'CD_REF' (depuis '{original_first_col_name}') et 'NOM LATIN' (depuis '{original_second_col_name}') avec d√©limiteur '{repr(delimiter)}'.")
                    break # Le bon d√©limiteur a √©t√© trouv√©, et les colonnes ont √©t√© renomm√©es avec succ√®s
                else: # Le renommage a √©chou√© pour une raison inconnue
                    df = None 
            else: # Moins de 2 colonnes lues
                df = None
        
        except pd.errors.EmptyDataError:
            st.error(f"Le fichier CSV '{csv_path}' est vide.")
            return None # Pas la peine d'essayer d'autres d√©limiteurs si le fichier est vide
        except FileNotFoundError: 
            st.error(f"Fichier CSV '{csv_path}' non trouv√©.")
            return None
        except Exception as e_read:
            if DEBUG_MODE:
                st.warning(f"[DEBUG load_cd_ref_data] √âchec de la lecture de '{csv_path}' avec d√©limiteur '{repr(delimiter)}': {e_read}")
            df = None # R√©initialiser df pour s'assurer que la boucle continue ou √©choue proprement

    # Apr√®s avoir essay√© tous les d√©limiteurs
    if df is not None and not df.empty:
        # S'assurer que les types de donn√©es sont corrects apr√®s s√©lection/renommage
        df["CD_REF"] = df["CD_REF"].astype(str)
        df["NOM LATIN"] = df["NOM LATIN"].astype(str)
        
        # Cr√©er la colonne normalis√©e pour la recherche
        df["NOM_LATIN_normalized"] = df["NOM LATIN"].str.strip().str.lower()
        
        # Supprimer les lignes o√π CD_REF ou NOM LATIN pourraient √™tre vides apr√®s le traitement
        df.dropna(subset=["CD_REF", "NOM LATIN"], inplace=True)
        df = df[df["CD_REF"].str.strip() != '']
        df = df[df["NOM LATIN"].str.strip() != '']

        if not df.empty:
            if DEBUG_MODE:
                st.info(f"[DEBUG load_cd_ref_data] Fichier CSV '{csv_path}' charg√© avec succ√®s. {len(df)} lignes valides apr√®s nettoyage. Colonnes: {df.columns.tolist()}")
            return df
        else:
            st.error(f"Apr√®s nettoyage, aucune donn√©e valide n'a √©t√© trouv√©e dans '{csv_path}'.")
            return None # Aucune donn√©e valide apr√®s nettoyage
            
    else: # df is None or df.empty
        st.error(f"Impossible de lire ou de traiter le fichier CSV '{csv_path}' pour identifier les colonnes 'CD_REF' et 'NOM LATIN'.")
        st.error("Veuillez v√©rifier les points suivants :")
        st.markdown("""
            - Le fichier `DATA_CD_REF.csv` est bien pr√©sent dans le m√™me r√©pertoire que le script.
            - La deuxi√®me ligne du fichier contient bien les en-t√™tes (par exemple, "CD_REF" et "NOM LATIN").
            - Le fichier utilise un d√©limiteur standard : virgule (,), tabulation (invisible, souvent copi√©e depuis Excel) ou point-virgule (;).
            - Le fichier n'est pas vide et contient des donn√©es exploitables.
        """)
        return None

TAXREF_DATA = load_cd_ref_data(CD_REF_CSV_PATH)

# -----------------------------------------------------------------------------
# Fonctions utilitaires
# -----------------------------------------------------------------------------

@st.cache_data(show_spinner=False, ttl=86_400)
def fetch_html(url: str, session: requests.Session | None = None) -> BeautifulSoup | None:
    """T√©l√©charge une page et renvoie son contenu analys√© par BeautifulSoup."""
    if DEBUG_MODE:
        st.info(f"[DEBUG fetch_html] Tentative de t√©l√©chargement de : {url}")
    sess = session or requests.Session()
    sess.headers.update(HEADERS)
    try:
        r = sess.get(url, timeout=15)
        r.raise_for_status()
        if DEBUG_MODE:
            st.info(f"[DEBUG fetch_html] Succ√®s du t√©l√©chargement de : {url} (status: {r.status_code})")
        return BeautifulSoup(r.text, "lxml")
    except requests.RequestException as e:
        st.warning(f"Erreur lors du t√©l√©chargement de {url}: {e}")
        return None

@st.cache_data(show_spinner=False, ttl=86_400)
def florealpes_search(species: str) -> str | None:
    """
    Recherche une esp√®ce sur FloreAlpes (requests+BeautifulSoup) en ciblant
    la "premi√®re option" pertinente sur la page de r√©sultats.
    """
    session = requests.Session()
    session.headers.update(HEADERS)
    base_url = "https://www.florealpes.com/"
    current_page_url_for_error_reporting = base_url 

    if DEBUG_MODE:
        st.info(f"[DEBUG FloreAlpes] D√©but recherche pour : {species}")

    try:
        try:
            home_resp = session.get(base_url, timeout=10)
            home_resp.raise_for_status()
            if DEBUG_MODE:
                st.info(f"[DEBUG FloreAlpes] Page d'accueil ({base_url}) charg√©e (status: {home_resp.status_code}).")
        except requests.RequestException as e:
            if DEBUG_MODE:
                st.info(f"[DEBUG FloreAlpes] Avertissement: Page d'accueil ({base_url}) non charg√©e: {e}")

        search_url = urljoin(base_url, "recherche.php")
        search_params = {"chaine": species}
        if DEBUG_MODE:
            st.info(f"[DEBUG FloreAlpes] Requ√™te de recherche vers : {search_url} avec params : {search_params}")
        
        results_response = session.get(search_url, params=search_params, timeout=15)
        results_response.raise_for_status()
        current_page_url_for_error_reporting = results_response.url
        if DEBUG_MODE:
            st.info(f"[DEBUG FloreAlpes] Page de r√©sultats charg√©e (status: {results_response.status_code}), URL: {current_page_url_for_error_reporting}")

        soup = BeautifulSoup(results_response.text, "lxml")
        page_text_lower = results_response.text.lower()
        no_results_messages = [
            "aucun r√©sultat √† votre requ√™te", 
            "pas de r√©sultats trouv√©s pour cette recherche", 
            "aucun taxon ne correspond √† votre recherche"
        ]
        if any(msg in page_text_lower for msg in no_results_messages):
            st.info(f"[FloreAlpes] Aucun r√©sultat trouv√© pour '{species}'.")
            return None

        link_tag = None
        results_table_container = soup.select_one("#principal div.conteneur_tab")
        results_table = None
        if results_table_container:
            results_table = results_table_container.select_one("table.resultats")
            if not results_table: 
                results_table = results_table_container.select_one("table")
        
        if results_table:
            if DEBUG_MODE:
                st.info(f"[DEBUG FloreAlpes] Table des r√©sultats trouv√©e. Recherche du premier lien de fiche...")
            data_rows = results_table.select("tbody > tr, tr") 
            for i, row in enumerate(data_rows):
                link_in_row = row.select_one("td.symb > a[href^='fiche_']")
                if link_in_row:
                    link_tag = link_in_row
                    if DEBUG_MODE:
                        st.info(f"[DEBUG FloreAlpes] Lien 'premi√®re option' trouv√© dans la ligne {i+1} de la table.")
                    break 
        elif DEBUG_MODE:
            st.warning("[DEBUG FloreAlpes] Aucune table de r√©sultats principale n'a pu √™tre identifi√©e.")
        
        if link_tag and link_tag.has_attr('href'):
            relative_url = link_tag['href']
            absolute_url = urljoin(results_response.url, relative_url)
            if DEBUG_MODE:
                st.info(f"[DEBUG FloreAlpes] URL de fiche construite : {absolute_url}")
            return absolute_url
        else:
            if DEBUG_MODE:
                st.warning("[DEBUG FloreAlpes] Logique 'premi√®re option' n'a pas trouv√© de lien direct. Application des fallbacks.")
            if "fiche_" in results_response.url and ".php" in results_response.url:
                st.info(f"[FloreAlpes] URL actuelle est d√©j√† une fiche (fallback 1) pour '{species}': {results_response.url}")
                return results_response.url

            generic_link_tag = soup.select_one("a[href^='fiche_']")
            if generic_link_tag and generic_link_tag.has_attr('href'):
                relative_url = generic_link_tag['href']
                absolute_url = urljoin(results_response.url, relative_url)
                st.warning(f"[FloreAlpes] Logique 'premi√®re option' √©chou√©e. Utilisation du 1er lien 'fiche_' (fallback 2) pour '{species}': {absolute_url}")
                return absolute_url
            
            st.error(f"[FloreAlpes] Impossible de trouver le lien de la fiche pour '{species}'.")
            return None

    except requests.RequestException as e:
        st.error(f"[FloreAlpes] Erreur de requ√™te pour '{species}': {e}")
        return None
    except Exception as e:
        st.error(f"[FloreAlpes] Erreur inattendue pour '{species}': {e} (URL: {current_page_url_for_error_reporting})")
        return None

def scrape_florealpes(url: str) -> tuple[str | None, pd.DataFrame | None]:
    """Extrait l‚Äôimage principale et le tableau des caract√©ristiques de la page FloreAlpes."""
    if DEBUG_MODE:
        st.info(f"[DEBUG scrape_florealpes] D√©but de l'extraction pour URL : {url}")
    soup = fetch_html(url) 
    if soup is None:
        return None, None
    
    img_url = None
    image_selectors = [
        "table.fiche img[src$='.jpg']", ".flotte-g img[src$='.jpg']", 
        "img.illustration_details[src$='.jpg']", "img[alt*='Photo principale'][src$='.jpg']",
        "div#photo_principale img[src$='.jpg']", "img[src*='/Photos/'][src$='.jpg']",
        "a[href$='.jpg'] > img[src$='.jpg']", "img[src$='.jpg'][width]", "img[src$='.jpg']"
    ]
    for selector in image_selectors:
        img_tag = soup.select_one(selector)
        if img_tag and img_tag.has_attr('src'):
            width_attr = img_tag.get('width', '9999') 
            try:
                if int(str(width_attr).replace('px','')) > 50 : 
                    img_src = img_tag['src']
                    img_url = urljoin(url, img_src)
                    if DEBUG_MODE:
                        st.info(f"[DEBUG scrape_florealpes] Image trouv√©e avec s√©lecteur '{selector}': {img_url}")
                    break 
            except ValueError: 
                img_src = img_tag['src'] 
                img_url = urljoin(url, img_src)
                if DEBUG_MODE:
                    st.info(f"[DEBUG scrape_florealpes] Image (width non num.) trouv√©e avec '{selector}': {img_url}")
                break

    data_tbl = None
    tbl = soup.find("table", class_="fiche") 
    
    if not tbl: 
        if DEBUG_MODE:
            st.info("[DEBUG scrape_florealpes] Tableau 'table.fiche' non trouv√©. Tentative alternative.")
        all_tables = soup.find_all("table")
        for potential_table in all_tables:
            text_content = potential_table.get_text(" ", strip=True).lower()
            keywords = ["famille", "floraison", "habitat", "description", "plante", "caract√®res", "altitude", "taille"]
            if sum(keyword in text_content for keyword in keywords) >= 2: 
                if any(len(tr.select("td")) == 2 for tr in potential_table.select("tr")):
                    tbl = potential_table
                    if DEBUG_MODE:
                        st.info("[DEBUG scrape_florealpes] Tableau alternatif trouv√©.")
                    break
    
    if tbl:
        rows = []
        for tr_element in tbl.select("tr"): 
            cells = tr_element.select("td")
            if len(cells) == 2:
                attribute = cells[0].get_text(separator=' ', strip=True)
                value = cells[1].get_text(separator=' ', strip=True)
                if attribute: 
                    rows.append([attribute, value])
        
        if rows:
            data_tbl = pd.DataFrame(rows, columns=["Attribut", "Valeur"])
            data_tbl = data_tbl[data_tbl["Attribut"].str.strip().astype(bool)] 
            if data_tbl.empty: 
                data_tbl = None 
                if DEBUG_MODE:
                    st.info("[DEBUG scrape_florealpes] Tableau extrait mais vide apr√®s nettoyage.")
            elif DEBUG_MODE:
                st.info(f"[DEBUG scrape_florealpes] Tableau extrait avec {len(data_tbl)} lignes.")
        elif DEBUG_MODE:
            st.info("[DEBUG scrape_florealpes] Tableau trouv√© mais aucune ligne (attribut/valeur) extraite.")
            
    elif DEBUG_MODE:
        st.warning("[DEBUG scrape_florealpes] Aucun tableau de caract√©ristiques trouv√©.")
            
    return img_url, data_tbl

def infoflora_url(species: str) -> str:
    """Construit l'URL InfoFlora pour une esp√®ce."""
    slug = species.lower().replace(" ", "-")
    return f"https://www.infoflora.ch/fr/flore/{slug}.html"

def tela_botanica_url(species: str) -> str | None:
    """Interroge l‚ÄôAPI eFlore de Tela Botanica pour l'URL de synth√®se."""
    api_url = (
        "https://api.tela-botanica.org/service:eflore:0.1/" "names:search?mode=exact&taxon="
        f"{quote_plus(species)}"
    )
    if DEBUG_MODE:
        st.info(f"[DEBUG Tela Botanica] Interrogation API eFlore pour '{species}': {api_url}")
    try:
        s = requests.Session()
        s.headers.update(HEADERS)
        response = s.get(api_url, timeout=10)
        response.raise_for_status()
        data = response.json()
        if not data: 
            if DEBUG_MODE: st.info(f"[DEBUG Tela Botanica] Aucune donn√©e API pour '{species}'.")
            return None
        if isinstance(data, list) and len(data) > 0 and isinstance(data[0], dict):
            nn = data[0].get("num_nomen")
            if nn:
                url = f"https://www.tela-botanica.org/bdtfx-nn-{nn}-synthese"
                if DEBUG_MODE: st.info(f"[DEBUG Tela Botanica] URL de synth√®se trouv√©e: {url}")
                return url
            else:
                if DEBUG_MODE: st.warning(f"[DEBUG Tela Botanica] 'num_nomen' non trouv√© pour '{species}'.")
                return None
        else:
            st.warning(f"[Tela Botanica] R√©ponse API eFlore inattendue pour '{species}'.")
            return None
    except requests.RequestException as e:
        st.warning(f"[Tela Botanica] Erreur API eFlore pour '{species}': {e}")
        return None
    except ValueError as e: 
        resp_text = response.text if 'response' in locals() and hasattr(response, 'text') else "N/A"
        st.warning(f"[Tela Botanica] Erreur JSON API eFlore pour '{species}': {e}. R√©ponse: {resp_text[:200]}...")
        return None

def get_cd_ref_from_csv(species_name: str) -> str | None:
    """R√©cup√®re le CD_REF √† partir du DataFrame TAXREF_DATA charg√© depuis le CSV."""
    if TAXREF_DATA is None:
        if DEBUG_MODE:
            st.warning("[DEBUG CD_REF CSV] DataFrame TAXREF_DATA non charg√©.")
        return None

    normalized_species_name = species_name.strip().lower()
    if DEBUG_MODE:
        st.info(f"[DEBUG CD_REF CSV] Recherche de '{normalized_species_name}' dans le CSV.")

    match = TAXREF_DATA[TAXREF_DATA["NOM_LATIN_normalized"] == normalized_species_name]

    if not match.empty:
        cd_ref = match["CD_REF"].iloc[0]
        if DEBUG_MODE:
            st.info(f"[DEBUG CD_REF CSV] CD_REF '{cd_ref}' trouv√© pour '{species_name}'.")
        return str(cd_ref)
    else:
        if DEBUG_MODE:
            st.warning(f"[DEBUG CD_REF CSV] Aucun CD_REF trouv√© pour '{species_name}' dans CSV.")
        return None

def openobs_embed(species: str) -> str:
    """G√©n√®re le HTML pour l'iframe OpenObs, utilisant le CD_REF du CSV si possible."""
    cd_ref = get_cd_ref_from_csv(species)
    if cd_ref:
        iframe_url = f"https://openobs.mnhn.fr/redirect/inpn/taxa/{cd_ref}?view=map"
        if DEBUG_MODE: st.info(f"[DEBUG OpenObs] Utilisation CD_REF {cd_ref} (CSV) pour iframe OpenObs.")
        return f"<iframe src='{iframe_url}' width='100%' height='100%' frameborder='0' style='min-height: 450px;'></iframe>"
    else:
        st.warning(f"[OpenObs] CD_REF non trouv√© dans CSV pour '{species}'. Tentative avec URL OpenObs par nom.")
        old_iframe_url = f"https://openobs.mnhn.fr/map.html?sp={quote_plus(species)}"
        return (
            f"<p style='color: orange; border: 1px solid orange; padding: 5px; border-radius: 3px;'>"
            f"Avertissement : CD_REF pour '{species}' non r√©cup√©r√© depuis CSV. Carte OpenObs bas√©e sur recherche par nom.</p>"
            f"<iframe src='{old_iframe_url}' width='100%' height='100%' frameborder='0' style='min-height: 400px;'></iframe>"
        )

def biodivaura_url(species: str) -> str:
    """Construit l'URL pour Biodiv'AURA Atlas, utilisant le CD_REF du CSV si possible."""
    cd_ref = get_cd_ref_from_csv(species)
    if cd_ref:
        direct_url = f"https://atlas.biodiversite-auvergne-rhone-alpes.fr/espece/{cd_ref}"
        if DEBUG_MODE: st.info(f"[DEBUG Biodiv'AURA] Utilisation CD_REF {cd_ref} (CSV) pour URL Biodiv'AURA.")
        return direct_url
    else:
        st.warning(f"[Biodiv'AURA] CD_REF non trouv√© dans CSV pour '{species}'. Utilisation URL de recherche.")
        search_url = f"https://atlas.biodiversite-auvergne-rhone-alpes.fr/recherche?keyword={quote_plus(species)}"
        return search_url

def inpn_species_url(species: str) -> str | None:
    """Construit l'URL de la fiche esp√®ce INPN en utilisant le CD_REF du CSV."""
    cd_ref = get_cd_ref_from_csv(species)
    if cd_ref:
        url = f"https://inpn.mnhn.fr/espece/cd_nom/{cd_ref}"
        if DEBUG_MODE: st.info(f"[DEBUG INPN] URL INPN construite avec CD_REF {cd_ref} (CSV): {url}")
        return url
    else:
        if DEBUG_MODE: st.warning(f"[DEBUG INPN] CD_REF non trouv√© dans CSV pour '{species}'. Lien de recherche INPN.")
        search_url_inpn = f"https://inpn.mnhn.fr/collTerr/nomenclature/espece/recherche?texteRecherche={quote_plus(species)}"
        return search_url_inpn

# -----------------------------------------------------------------------------
# Interface utilisateur Streamlit
# -----------------------------------------------------------------------------

col_keep_section, col_main_title = st.columns([1, 3], gap="large")
with col_keep_section:
    st.markdown("##### üìù Notes de Projet")
    keep_url = "https://keep.google.com/#NOTE/1dHuU90VKwWzZAgoXzTsjNiRp_QgDB1BRCfthK5hH-23Vxb_A86uTPrroczclhg"
    st.markdown("Lien direct vers la note Google Keep :")
    button_html = f"""
    <a href="{keep_url}" target="_blank"
        style="display: inline-block; padding: 0.4em 0.8em; margin-top: 0.5em; background-color: #E8E8E8; color: #31333F;
               text-align: center; text-decoration: none; border-radius: 0.25rem; font-weight: 500;
               border: 1px solid #B0B0B0;">Acc√©der √† la note Google Keep</a>"""
    st.markdown(button_html, unsafe_allow_html=True)
    st.caption("S'ouvrira dans un nouvel onglet.")

with col_main_title:
    st.title("üåø Recherche Infos Esp√®ces") 

if DEBUG_MODE:
    st.sidebar.info("Mode D√©bogage Activ√©", icon="üõ†Ô∏è")
    st.sidebar.markdown("Ajoutez `?debug=true` √† l'URL pour activer les logs d√©taill√©s.")
    if TAXREF_DATA is None:
        st.sidebar.error("Fichier CSV des CD_REF non charg√©. V√©rifiez les messages d'erreur.")
    elif TAXREF_DATA.empty:
        st.sidebar.warning("Fichier CSV des CD_REF charg√© mais vide ou sans donn√©es valides.")
    else:
        st.sidebar.success(f"{len(TAXREF_DATA)} taxons charg√©s depuis le CSV.")

st.markdown("---") 
st.markdown("Saisissez les noms scientifiques (un par ligne) puis lancez la recherche.")
input_txt = st.text_area(
    "Liste d‚Äôesp√®ces", 
    placeholder="Exemples :\nLamium purpureum\nTrifolium alpinum\nVicia sativa\nAbies alba", 
    height=150 
)

if 'button_clicked' not in st.session_state:
    st.session_state.button_clicked = False

button_pressed = st.button("üöÄ Lancer la recherche", type="primary")
if button_pressed:
    st.session_state.button_clicked = True

if st.session_state.button_clicked and input_txt.strip():
    species_list = [s.strip() for s in input_txt.splitlines() if s.strip()]
    if DEBUG_MODE:
        st.info(f"[DEBUG Main] Esp√®ces √† rechercher : {species_list}")

    for sp_idx, sp in enumerate(species_list):
        st.subheader(f"{sp_idx + 1}. {sp}")
        st.markdown("---")
        col_map, col_intro = st.columns([2, 1]) 

        with col_map:
            st.markdown("##### üó∫Ô∏è Carte de r√©partition (OpenObs/INPN)")
            with st.spinner(f"Chargement carte OpenObs pour '{sp}'..."):
                html_openobs_main = openobs_embed(sp)
            st.components.v1.html(html_openobs_main, height=465)

        with col_intro:
            st.markdown("##### ‚ÑπÔ∏è Sources d'Information")
            st.info("Infos d√©taill√©es dans les onglets ci-dessous. Messages de debug/erreur affich√©s au fur et √† mesure.")
        
        st.markdown("<br>", unsafe_allow_html=True) 
        tab_names = ["FloreAlpes", "InfoFlora", "Tela Botanica", "Biodiv'AURA", "INPN"]
        tab_fa, tab_if, tab_tb, tab_ba, tab_inpn = st.tabs(tab_names)

        with tab_fa:
            st.markdown("##### FloreAlpes")
            with st.spinner(f"Recherche '{sp}' sur FloreAlpes..."):
                url_fa = florealpes_search(sp) 
            if url_fa:
                st.markdown(f"**FloreAlpes** : [Fiche compl√®te]({url_fa})")
                with st.spinner(f"Extraction donn√©es FloreAlpes pour '{sp}'..."):
                    img, tbl = scrape_florealpes(url_fa)
                if img:
                    st.image(img, caption=f"{sp} (Source: FloreAlpes)", use_column_width="auto")
                else:
                    st.warning(f"Image non trouv√©e sur FloreAlpes pour '{sp}'.")
                if tbl is not None and not tbl.empty:
                    st.dataframe(tbl, hide_index=True, use_container_width=True)
                elif tbl is not None and tbl.empty: 
                    st.info(f"Tableau caract√©ristiques vide sur FloreAlpes pour '{sp}'.")
                else: 
                    st.warning(f"Tableau caract√©ristiques non trouv√© sur FloreAlpes pour '{sp}'.")
            else:
                st.error(f"Fiche introuvable sur FloreAlpes pour '{sp}'.")

        with tab_if:
            st.markdown("##### InfoFlora")
            url_if = infoflora_url(sp)
            st.markdown(f"**InfoFlora** : [Fiche compl√®te]({url_if})")
            with st.spinner(f"Chargement page InfoFlora pour '{sp}'..."):
                st.components.v1.iframe(src=url_if, height=600, scrolling=True)

        with tab_tb:
            st.markdown("##### Tela Botanica (eFlore)")
            with st.spinner(f"Recherche API Tela Botanica pour '{sp}'..."):
                url_tb = tela_botanica_url(sp)
            if url_tb:
                st.markdown(f"**Tela Botanica** : [Synth√®se eFlore]({url_tb})")
                with st.spinner(f"Chargement page Tela Botanica pour '{sp}'..."):
                    st.components.v1.iframe(src=url_tb, height=600, scrolling=True)
            else:
                st.warning(f"Aucune correspondance API eFlore (Tela Botanica) pour '{sp}'.")

        with tab_ba:
            st.markdown("##### Biodiv'AURA Atlas")
            with st.spinner(f"Recherche Biodiv'AURA Atlas pour '{sp}'..."):
                url_ba_val = biodivaura_url(sp)
            st.markdown(f"**Biodiv'AURA** : [Acc√©der √† l‚Äôatlas]({url_ba_val})")
            with st.spinner(f"Chargement page Biodiv'AURA pour '{sp}'..."):
                st.components.v1.iframe(src=url_ba_val, height=600, scrolling=True)
        
        with tab_inpn:
            st.markdown("##### INPN - Inventaire National du Patrimoine Naturel")
            with st.spinner(f"Recherche infos INPN pour '{sp}'..."):
                url_inpn_val = inpn_species_url(sp)
            if url_inpn_val:
                st.markdown(f"**INPN** : [Fiche esp√®ce INPN]({url_inpn_val})")
                if "cd_nom" in url_inpn_val: 
                    with st.spinner(f"Chargement page INPN pour '{sp}'..."):
                        st.components.v1.iframe(src=url_inpn_val, height=600, scrolling=True)
                else: 
                    st.info("URL INPN est une page de recherche. Affichage direct non tent√©. Utilisez le lien ci-dessus.")
            else: 
                st.error(f"Impossible de g√©n√©rer un lien INPN pour '{sp}'.")
        st.markdown("---")

elif st.session_state.button_clicked and not input_txt.strip():
    st.warning("Veuillez saisir au moins un nom d'esp√®ce.")
    st.session_state.button_clicked = False 
else:
    if not st.session_state.button_clicked : 
        st.info("Saisissez au moins une esp√®ce pour d√©marrer la recherche.")
